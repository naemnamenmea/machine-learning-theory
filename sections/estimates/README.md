## Cross validation (CV)

В качестве основной вспомогательной библиотеки будем использовать **sklearn**.

Возьмем модели **KNeighborsClassifier** и  **SVC** для задач классификации. Для задач восстановления регрессии &mdash; **ExtraTreeRegressor** и выборки **boston**, **wine** и **diabetes**.
 
<table>
    <tr>
        <th rowspan="2">properties
        </th>
        <th colspan="3">datasets</th>
    </tr>
    <tr>
        <td>diabetes
        </td>
        <td>wine
        </td>
        <td>digits
        </td>  
    </tr>
    <tr>
        <td>Classes
        </td>
        <td>-
        </td>
        <td>3
        </td>
        <td>10
        </td>
    </tr>
    <tr>
        <td>Samples per class
        </td>
        <td>-
        </td>
        <td>[59,71,48]
        </td>
        <td>~180
        </td>
    </tr>
    <tr>
        <td>Samples total
        </td>
        <td>442
        </td>
        <td>178
        </td>
        <td>1797
        </td>
    </tr>
    <tr>
        <td>Dimensionality
        </td>
        <td>10
        </td>
        <td>13
        </td>
        <td>64
        </td>
    </tr>
    <tr>
        <td>Features
        </td>
        <td>real, -.2 < x < .2
        </td>
        <td>real, positive
        </td>
        <td>integers 0-16
        </td>
    </tr>
    </tr>
    <tr>
        <td>Targets
        </td>
        <td>integer 25 - 346
        </td>
        <td>-
        </td>
        <td>-
        </td>
    </tr>
</table>

Давайте подробнее рассмотрим что из себя представляют эти кросс-валидаторы:

* Они принимают на вход модель и выборку. 
* Их задача состоит в том, чтобы проверить качество модели на данной выборке (а именно ее обобщающую способность, т.е. как будет себя вести обученная модель на "боевых" данных). 
* Единственное чем кросс-валидаторы отличаются друг от друга - так это способом разбиения выборки на *train* и *test*.

А теперь взглянем им в лицо:

**LOO** &mdash; каждый объект выборки участвует в контроле ровно один раз, что плохо.

**ShuffleSplit** &mdash; контроль по случайным подвыборкам. Задается размер тестовой выборки (*k*) и количество итераций. На каждой итерации генерируются случайные подвыборки (размер тестовой и обучающей выборок всегда одинаков и зависит от параметра *k*).

**CCV** &mdash; в контроле участвуют все возможные наборы подвыборок.

**Bootstrap** &mdash; напоминает контроль по случайным подвыборкам. Отличие в том, что объекты выбираются с возвращением (т.е. могут образовываться повторы). Отлично подходит для кросс-валидации выборок малого размера.

**RepeatedKFold** &mdash; *t* раз выборка разбивается на *k* блоков, каждый из которых поочередно берет на себя роль тестовой выборки. *Де-факто стандарт для оценивания моделей.*

Ниже показаны оценки, которые выдали нам кросс-валидаторы для разных моделей на разных выборках:

<table>
    <tr>
        <th rowspan="2">cv
        </th>
        <th colspan="3">score</th>
    </tr>
    <tr>
        <td>diabetes / r <br> <i>SVR</i>
        </td>
        <td>wine / c <br> <i>KNeighborsClassifier</i>
        </td>
        <td>digits / c <br> <i>DecisionTreeClassifier</i>
        </td>  
    </tr>
    <tr>
        <td>LOO
        </td>
        <td>0.000000
        </td>
        <td>0.893258
        </td>
        <td>0.851419
        </td>
    </tr>
    <tr>
        <td>ShuffleSplit
        </td>
        <td>0.033107
        </td>
        <td>0.877778
        </td>
        <td>0.844722
        </td>
    </tr>
    <tr>
        <td>CCV
        </td>
        <td>0.000000
        </td>
        <td>0.932584
        </td>
        <td>0.861436
        </td>
    </tr>
    <tr>
        <td>Bootstrap
        </td>
        <td>0.058974
        </td>
        <td>0.876340
        </td>
        <td>0.839315
        </td>
    </tr>
    <tr>
        <td>RepeatedKFold
        </td>
        <td>0.041416
        </td>
        <td>0.904739
        </td>
        <td>0.849451
        </td>
    </tr>
</table>

Как видно из таблицы, *LOO* выделяются среди остальных, особенно это заметно на выборке *diabetes*.
